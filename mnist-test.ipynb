{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\conda\\lib\\importlib\\_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "D:\\conda\\lib\\importlib\\_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "D:\\conda\\lib\\importlib\\_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "D:\\conda\\lib\\importlib\\_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "D:\\conda\\lib\\importlib\\_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "from scipy import io as scio\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import skimage.transform as sktransform\n",
    "from skimage.filters import threshold_otsu, threshold_sauvola\n",
    "from skimage import feature\n",
    "from tqdm import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = scio.loadmat('./mnist-original.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_data = data['data']\n",
    "label_data = data['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784, 70000)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 70000)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "img_sample = np.reshape(img_data[:, 0], [28, 28])\n",
    "plt.imshow(img_sample, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(70000, 784)\n",
      "(70000, 1)\n"
     ]
    }
   ],
   "source": [
    "dataset = img_data.T\n",
    "label = label_data.T\n",
    "print(dataset.shape)\n",
    "print(label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features_list(img):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        path : string :要进行特征提取的图片路径\n",
    "    Return:\n",
    "        feature_list : dict : 包含三种特征的字典\n",
    "    \"\"\"\n",
    "    gray_image = img\n",
    "    otsu_threshold = threshold_otsu(gray_image)\n",
    "    bin_image = gray_image > otsu_threshold\n",
    "    # 此处分别使用了水平、竖直、以及45 和135 度方向求 GLCM特征\n",
    "    feature_glcm = feature.greycomatrix(gray_image, [3], [0, np.pi / 4, np.pi / 2, 3 * np.pi / 4], levels=256)\n",
    "    hog_feature_vector, hog_image = feature.hog(gray_image, orientations=8, pixels_per_cell=(5, 5),\n",
    "                                                cells_per_block=(1, 1), visualize=True, block_norm='L2-Hys',\n",
    "                                                feature_vector=True)\n",
    "    # 设置LBP 特征提取算法的参数\n",
    "    radius = 3\n",
    "    n_points = 8 * radius\n",
    "    #print(gray_image.dtype)\n",
    "    feature_lbp = feature.local_binary_pattern(bin_image, n_points, radius, 'uniform')\n",
    "    feature_glcm_flattened = feature_glcm.flatten()\n",
    "    feature_hog_flattened = hog_feature_vector\n",
    "    feature_lbp_flattended = feature_lbp.flatten()\n",
    "    result = {'glcm': feature_glcm_flattened, 'hog': feature_hog_flattened, 'lbp': feature_lbp_flattended}\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lbp_feature = []\n",
    "glcm_feature = []\n",
    "hog_feature = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for img in tqdm(dataset):\n",
    "    image = np.reshape(img, [28, 28])\n",
    "    features = get_features_list(image)\n",
    "    lbp_feature.append(features['lbp'])\n",
    "#     lbp_feature.append(features['glcm'])\n",
    "#     lbp_feature.append(features['hog'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lbp_feature = np.array(lbp_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lbp_feature.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(lbp_feature, label, test_size=0.3, random_state=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_img = np.reshape(dataset[19999, :], [28, 28])\n",
    "plt.imshow(test_img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lbp = get_features_list(test_img)['lbp']\n",
    "lbp = np.reshape(lbp, [1, lbp.shape[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.predict(lbp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lbp_img = np.reshape(lbp, [28,28])\n",
    "plt.imshow(lbp_img, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 使用keras 搭建一个简单的CNN 来实现分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Conv1D, Conv2D, MaxPool1D, MaxPool2D, Softmax, GlobalAveragePooling2D, Dense\n",
    "from keras.optimizers import SGD\n",
    "from keras.callbacks import TensorBoard, ReduceLROnPlateau, ModelCheckpoint\n",
    "from keras.models import Model\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    input_tensor = Input(shape=(28, 28, 1))\n",
    "    x = Conv2D(filters=64 ,kernel_size=(1,1) ,strides=(1, 1), activation='relu')(input_tensor)\n",
    "    x = MaxPool2D(pool_size=(1, 1), strides=(2,2))(x)\n",
    "    \n",
    "    x = Conv2D(filters=128,kernel_size=(3,3), strides=(1, 1), activation='relu')(x)\n",
    "    x = MaxPool2D(pool_size=(2, 2), strides=(2, 2))(x)\n",
    "    \n",
    "    x = Conv2D(filters=256,kernel_size=(3,3), strides=(1, 1), activation='relu')(x)\n",
    "    x = MaxPool2D(pool_size=(2, 2), strides=(2, 2))(x)     \n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    y = Dense(10,activation='softmax')(x)\n",
    "    model = Model(input=input_tensor, outputs=y)\n",
    "    optimizer = SGD(learning_rate=0.001, momentum=0.9)\n",
    "    model.compile(optimizer=optimizer, loss='categorical_crossentropy')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\conda\\lib\\site-packages\\ipykernel_launcher.py:14: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=Tensor(\"de..., inputs=Tensor(\"in...)`\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "model = get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_13\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_18 (InputLayer)        (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_47 (Conv2D)           (None, 28, 28, 64)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_46 (MaxPooling (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_48 (Conv2D)           (None, 12, 12, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_47 (MaxPooling (None, 6, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_49 (Conv2D)           (None, 4, 4, 256)         295168    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_48 (MaxPooling (None, 2, 2, 256)         0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_15  (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 437,514\n",
      "Trainable params: 437,514\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70000, 10)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_one_hot = to_categorical(label)\n",
    "y_one_hot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_img = np.reshape(dataset, [dataset.shape[0], 28, 28, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70000, 28, 28, 1)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(<matplotlib.image.AxesImage at 0x18855b46688>, None)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.imshow(dataset_img[0][:,:,0]),plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "tb = TensorBoard(log_dir='./log', write_graph=True)\n",
    "model_save = ModelCheckpoint('./model/Mnist-CNN-model.h5',\n",
    "                             monitor='val_loss',\n",
    "                             verbose=100,\n",
    "                             save_best_only=True,\n",
    "                             save_weights_only=True, \n",
    "                             mode='auto',\n",
    "                             period=10)\n",
    "lr_reduce = ReduceLROnPlateau(monitor='val_loss', \n",
    "                              factor=0.1, \n",
    "                              patience=10,\n",
    "                              verbose=0, \n",
    "                              mode='auto',\n",
    "                              min_delta=0.0001, \n",
    "                              min_lr=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(dataset_img, y_one_hot, test_size=0.3, random_state=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49000, 28, 28, 1)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "49000/49000 [==============================] - ETA: 1:31 - loss: 13.95 - ETA: 1:16 - loss: 16.15 - ETA: 1:11 - loss: 18.66 - ETA: 1:07 - loss: 20.95 - ETA: 1:05 - loss: 21.52 - ETA: 1:04 - loss: 20.38 - ETA: 1:02 - loss: 18.70 - ETA: 1:01 - loss: 16.87 - ETA: 1:00 - loss: 15.32 - ETA: 1:00 - loss: 14.04 - ETA: 59s - loss: 13.0017 - ETA: 58s - loss: 12.127 - ETA: 58s - loss: 11.381 - ETA: 57s - loss: 10.747 - ETA: 57s - loss: 10.196 - ETA: 56s - loss: 9.712 - ETA: 56s - loss: 9.28 - ETA: 55s - loss: 8.89 - ETA: 55s - loss: 8.54 - ETA: 54s - loss: 8.23 - ETA: 53s - loss: 7.95 - ETA: 53s - loss: 7.69 - ETA: 52s - loss: 7.46 - ETA: 52s - loss: 7.24 - ETA: 51s - loss: 7.04 - ETA: 51s - loss: 6.86 - ETA: 50s - loss: 6.69 - ETA: 50s - loss: 6.54 - ETA: 49s - loss: 6.39 - ETA: 48s - loss: 6.25 - ETA: 48s - loss: 6.13 - ETA: 47s - loss: 6.01 - ETA: 47s - loss: 5.89 - ETA: 46s - loss: 5.79 - ETA: 46s - loss: 5.69 - ETA: 45s - loss: 5.59 - ETA: 45s - loss: 5.51 - ETA: 44s - loss: 5.42 - ETA: 44s - loss: 5.34 - ETA: 43s - loss: 5.26 - ETA: 43s - loss: 5.19 - ETA: 42s - loss: 5.12 - ETA: 42s - loss: 5.06 - ETA: 41s - loss: 4.99 - ETA: 41s - loss: 4.93 - ETA: 40s - loss: 4.88 - ETA: 39s - loss: 4.82 - ETA: 39s - loss: 4.77 - ETA: 38s - loss: 4.72 - ETA: 38s - loss: 4.67 - ETA: 37s - loss: 4.62 - ETA: 37s - loss: 4.58 - ETA: 36s - loss: 4.54 - ETA: 36s - loss: 4.49 - ETA: 35s - loss: 4.45 - ETA: 35s - loss: 4.42 - ETA: 34s - loss: 4.38 - ETA: 34s - loss: 4.34 - ETA: 33s - loss: 4.31 - ETA: 33s - loss: 4.27 - ETA: 32s - loss: 4.24 - ETA: 32s - loss: 4.21 - ETA: 31s - loss: 4.18 - ETA: 31s - loss: 4.15 - ETA: 30s - loss: 4.12 - ETA: 29s - loss: 4.09 - ETA: 29s - loss: 4.06 - ETA: 28s - loss: 4.04 - ETA: 28s - loss: 4.01 - ETA: 27s - loss: 3.99 - ETA: 27s - loss: 3.96 - ETA: 26s - loss: 3.94 - ETA: 26s - loss: 3.92 - ETA: 25s - loss: 3.89 - ETA: 25s - loss: 3.87 - ETA: 24s - loss: 3.85 - ETA: 24s - loss: 3.83 - ETA: 23s - loss: 3.81 - ETA: 23s - loss: 3.79 - ETA: 22s - loss: 3.77 - ETA: 22s - loss: 3.75 - ETA: 21s - loss: 3.73 - ETA: 20s - loss: 3.72 - ETA: 20s - loss: 3.70 - ETA: 19s - loss: 3.68 - ETA: 19s - loss: 3.66 - ETA: 18s - loss: 3.65 - ETA: 18s - loss: 3.63 - ETA: 17s - loss: 3.61 - ETA: 17s - loss: 3.60 - ETA: 16s - loss: 3.58 - ETA: 16s - loss: 3.57 - ETA: 15s - loss: 3.55 - ETA: 15s - loss: 3.54 - ETA: 14s - loss: 3.52 - ETA: 14s - loss: 3.51 - ETA: 13s - loss: 3.49 - ETA: 12s - loss: 3.48 - ETA: 12s - loss: 3.46 - ETA: 11s - loss: 3.45 - ETA: 11s - loss: 3.43 - ETA: 10s - loss: 3.42 - ETA: 10s - loss: 3.41 - ETA: 9s - loss: 3.3968 - ETA: 9s - loss: 3.382 - ETA: 8s - loss: 3.368 - ETA: 8s - loss: 3.354 - ETA: 7s - loss: 3.341 - ETA: 7s - loss: 3.327 - ETA: 6s - loss: 3.313 - ETA: 6s - loss: 3.299 - ETA: 5s - loss: 3.285 - ETA: 5s - loss: 3.271 - ETA: 4s - loss: 3.257 - ETA: 3s - loss: 3.243 - ETA: 3s - loss: 3.228 - ETA: 2s - loss: 3.214 - ETA: 2s - loss: 3.199 - ETA: 1s - loss: 3.185 - ETA: 1s - loss: 3.170 - ETA: 0s - loss: 3.155 - ETA: 0s - loss: 3.140 - 65s 1ms/step - loss: 3.1329\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\conda\\lib\\site-packages\\keras\\callbacks\\callbacks.py:1042: RuntimeWarning: Reduce LR on plateau conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
      "  (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/2\n",
      "49000/49000 [==============================] - ETA: 1:05 - loss: 1.220 - ETA: 1:03 - loss: 1.188 - ETA: 1:03 - loss: 1.190 - ETA: 1:03 - loss: 1.162 - ETA: 1:02 - loss: 1.134 - ETA: 1:02 - loss: 1.112 - ETA: 1:01 - loss: 1.082 - ETA: 1:00 - loss: 1.060 - ETA: 1:00 - loss: 1.044 - ETA: 59s - loss: 1.033 - ETA: 59s - loss: 1.01 - ETA: 58s - loss: 0.99 - ETA: 58s - loss: 0.98 - ETA: 57s - loss: 0.95 - ETA: 57s - loss: 0.94 - ETA: 56s - loss: 0.92 - ETA: 56s - loss: 0.91 - ETA: 55s - loss: 0.89 - ETA: 55s - loss: 0.88 - ETA: 54s - loss: 0.86 - ETA: 54s - loss: 0.85 - ETA: 53s - loss: 0.84 - ETA: 52s - loss: 0.83 - ETA: 52s - loss: 0.82 - ETA: 51s - loss: 0.81 - ETA: 51s - loss: 0.80 - ETA: 50s - loss: 0.78 - ETA: 50s - loss: 0.78 - ETA: 49s - loss: 0.76 - ETA: 49s - loss: 0.76 - ETA: 48s - loss: 0.75 - ETA: 48s - loss: 0.74 - ETA: 47s - loss: 0.73 - ETA: 47s - loss: 0.72 - ETA: 46s - loss: 0.71 - ETA: 46s - loss: 0.70 - ETA: 45s - loss: 0.70 - ETA: 45s - loss: 0.69 - ETA: 44s - loss: 0.68 - ETA: 43s - loss: 0.67 - ETA: 43s - loss: 0.67 - ETA: 42s - loss: 0.66 - ETA: 42s - loss: 0.65 - ETA: 41s - loss: 0.65 - ETA: 41s - loss: 0.64 - ETA: 40s - loss: 0.63 - ETA: 40s - loss: 0.63 - ETA: 39s - loss: 0.62 - ETA: 39s - loss: 0.62 - ETA: 38s - loss: 0.61 - ETA: 38s - loss: 0.60 - ETA: 37s - loss: 0.60 - ETA: 37s - loss: 0.59 - ETA: 36s - loss: 0.59 - ETA: 36s - loss: 0.58 - ETA: 35s - loss: 0.58 - ETA: 34s - loss: 0.58 - ETA: 34s - loss: 0.57 - ETA: 33s - loss: 0.57 - ETA: 33s - loss: 0.56 - ETA: 32s - loss: 0.56 - ETA: 32s - loss: 0.56 - ETA: 31s - loss: 0.55 - ETA: 31s - loss: 0.55 - ETA: 30s - loss: 0.54 - ETA: 30s - loss: 0.54 - ETA: 29s - loss: 0.54 - ETA: 29s - loss: 0.53 - ETA: 28s - loss: 0.53 - ETA: 28s - loss: 0.53 - ETA: 27s - loss: 0.53 - ETA: 27s - loss: 0.53 - ETA: 26s - loss: 0.52 - ETA: 25s - loss: 0.52 - ETA: 25s - loss: 0.52 - ETA: 24s - loss: 0.52 - ETA: 24s - loss: 0.52 - ETA: 23s - loss: 0.51 - ETA: 23s - loss: 0.51 - ETA: 22s - loss: 0.51 - ETA: 22s - loss: 0.51 - ETA: 21s - loss: 0.51 - ETA: 21s - loss: 0.51 - ETA: 20s - loss: 0.50 - ETA: 20s - loss: 0.50 - ETA: 19s - loss: 0.50 - ETA: 19s - loss: 0.50 - ETA: 18s - loss: 0.50 - ETA: 17s - loss: 0.49 - ETA: 17s - loss: 0.49 - ETA: 16s - loss: 0.49 - ETA: 16s - loss: 0.49 - ETA: 15s - loss: 0.49 - ETA: 15s - loss: 0.48 - ETA: 14s - loss: 0.48 - ETA: 14s - loss: 0.48 - ETA: 13s - loss: 0.48 - ETA: 13s - loss: 0.48 - ETA: 12s - loss: 0.47 - ETA: 12s - loss: 0.47 - ETA: 11s - loss: 0.47 - ETA: 11s - loss: 0.47 - ETA: 10s - loss: 0.47 - ETA: 9s - loss: 0.4682 - ETA: 9s - loss: 0.466 - ETA: 8s - loss: 0.464 - ETA: 8s - loss: 0.461 - ETA: 7s - loss: 0.459 - ETA: 7s - loss: 0.457 - ETA: 6s - loss: 0.455 - ETA: 6s - loss: 0.454 - ETA: 5s - loss: 0.452 - ETA: 5s - loss: 0.450 - ETA: 4s - loss: 0.448 - ETA: 4s - loss: 0.447 - ETA: 3s - loss: 0.445 - ETA: 2s - loss: 0.444 - ETA: 2s - loss: 0.442 - ETA: 1s - loss: 0.440 - ETA: 1s - loss: 0.439 - ETA: 0s - loss: 0.437 - ETA: 0s - loss: 0.435 - 66s 1ms/step - loss: 0.4344\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x188614c0948>"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train ,batch_size=400,epochs=2,verbose=1,\n",
    "         callbacks=[lr_reduce, model_save])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21000/21000 [==============================] - ETA: 11 - ETA: 16 - ETA: 17 - ETA: 18 - ETA: 19 - ETA: 19 - ETA: 19 - ETA: 19 - ETA: 19 - ETA: 19 - ETA: 19 - ETA: 19 - ETA: 19 - ETA: 19 - ETA: 19 - ETA: 19 - ETA: 19 - ETA: 19 - ETA: 19 - ETA: 19 - ETA: 19 - ETA: 19 - ETA: 19 - ETA: 19 - ETA: 19 - ETA: 19 - ETA: 19 - ETA: 19 - ETA: 19 - ETA: 19 - ETA: 19 - ETA: 19 - ETA: 19 - ETA: 19 - ETA: 19 - ETA: 19 - ETA: 19 - ETA: 19 - ETA: 19 - ETA: 18 - ETA: 18 - ETA: 18 - ETA: 18 - ETA: 18 - ETA: 18 - ETA: 18 - ETA: 18 - ETA: 18 - ETA: 18 - ETA: 18 - ETA: 18 - ETA: 18 - ETA: 18 - ETA: 18 - ETA: 18 - ETA: 18 - ETA: 18 - ETA: 17 - ETA: 17 - ETA: 17 - ETA: 17 - ETA: 17 - ETA: 17 - ETA: 17 - ETA: 17 - ETA: 17 - ETA: 17 - ETA: 17 - ETA: 17 - ETA: 17 - ETA: 17 - ETA: 16 - ETA: 16 - ETA: 16 - ETA: 16 - ETA: 16 - ETA: 16 - ETA: 16 - ETA: 16 - ETA: 16 - ETA: 16 - ETA: 16 - ETA: 16 - ETA: 16 - ETA: 16 - ETA: 16 - ETA: 15 - ETA: 15 - ETA: 15 - ETA: 15 - ETA: 15 - ETA: 15 - ETA: 15 - ETA: 15 - ETA: 15 - ETA: 15 - ETA: 15 - ETA: 15 - ETA: 15 - ETA: 15 - ETA: 15 - ETA: 15 - ETA: 14 - ETA: 14 - ETA: 14 - ETA: 14 - ETA: 14 - ETA: 14 - ETA: 14 - ETA: 14 - ETA: 14 - ETA: 14 - ETA: 14 - ETA: 14 - ETA: 14 - ETA: 14 - ETA: 14 - ETA: 13 - ETA: 13 - ETA: 13 - ETA: 13 - ETA: 13 - ETA: 13 - ETA: 13 - ETA: 13 - ETA: 13 - ETA: 13 - ETA: 13 - ETA: 13 - ETA: 13 - ETA: 13 - ETA: 13 - ETA: 12 - ETA: 12 - ETA: 12 - ETA: 12 - ETA: 12 - ETA: 12 - ETA: 12 - ETA: 12 - ETA: 12 - ETA: 12 - ETA: 12 - ETA: 12 - ETA: 12 - ETA: 12 - ETA: 12 - ETA: 11 - ETA: 11 - ETA: 11 - ETA: 11 - ETA: 11 - ETA: 11 - ETA: 11 - ETA: 11 - ETA: 11 - ETA: 11 - ETA: 11 - ETA: 11 - ETA: 11 - ETA: 11 - ETA: 10 - ETA: 10 - ETA: 10 - ETA: 10 - ETA: 10 - ETA: 10 - ETA: 10 - ETA: 10 - ETA: 10 - ETA: 10 - ETA: 10 - ETA: 10 - ETA: 10 - ETA: 10 - ETA: 10 - ETA: 9 - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - 22s 1ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.2186149250240553"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_label = np.array([np.argmax(d) for d in y_test])\n",
    "y_pre_label = np.array([np.argmax(d) for d in pred])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21000,)\n",
      "(21000,)\n"
     ]
    }
   ],
   "source": [
    "print(y_test_label.shape)\n",
    "print(y_pre_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9355238095238095"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test_label, y_pre_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 28, 28, 1)"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sample = X_test[1001, :, :, :]\n",
    "test_sample = np.reshape(test_sample, [1, test_sample.shape[0], test_sample.shape[1], test_sample.shape[2]])\n",
    "test_sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6.7172768e-05 2.3228847e-06 6.6676665e-05 1.5833306e-03 6.2200324e-06\n",
      "  1.9191639e-02 7.9360162e-04 9.5396308e-07 9.7817695e-01 1.1110102e-04]]\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "test_result = model.predict(test_sample)\n",
    "print(test_result)\n",
    "print(np.argmax(test_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(<matplotlib.image.AxesImage at 0x18847280ac8>, None)"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.imshow(test_sample[0, :,:, 0]),plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 使用预训练的模型进行分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.applications.vgg16 import VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import fashion_mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pretrained_model():\n",
    "    input_tensor = Input(shape=(32, 32, 3))\n",
    "    base_model = VGG16(include_top=False, weights='imagenet', input_tensor=input_tensor, pooling='avg',classes=10)\n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(1024, activation='relu')(x)\n",
    "    y = Dense(10, activation='softmax')(x)\n",
    "    model = Model(inputs=base_model.input, outputs= y)\n",
    "    model.compile(optimizer='rmsprop', loss='categorical_crossentropy')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n"
     ]
    }
   ],
   "source": [
    "model_vgg = get_pretrained_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
