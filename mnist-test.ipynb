{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import io as scio\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import skimage.transform as sktransform\n",
    "from skimage.filters import threshold_otsu, threshold_sauvola\n",
    "from skimage import feature\n",
    "from tqdm import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = scio.loadmat('./mnist-original.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_data = data['data']\n",
    "label_data = data['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_data = img_data / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784, 70000)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 70000)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "img_sample = np.reshape(img_data[:, 0], [28, 28])\n",
    "plt.imshow(img_sample, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(70000, 784)\n",
      "(70000, 1)\n"
     ]
    }
   ],
   "source": [
    "dataset = img_data.T\n",
    "label = label_data.T\n",
    "print(dataset.shape)\n",
    "print(label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features_list(img):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        path : string :要进行特征提取的图片路径\n",
    "    Return:\n",
    "        feature_list : dict : 包含三种特征的字典\n",
    "    \"\"\"\n",
    "    gray_image = img\n",
    "    otsu_threshold = threshold_otsu(gray_image)\n",
    "    bin_image = gray_image > otsu_threshold\n",
    "    # 此处分别使用了水平、竖直、以及45 和135 度方向求 GLCM特征\n",
    "#     feature_glcm = feature.greycomatrix(gray_image, [3], [0, np.pi / 4, np.pi / 2, 3 * np.pi / 4], levels=256)\n",
    "#     hog_feature_vector, hog_image = feature.hog(gray_image, orientations=8, pixels_per_cell=(5, 5),\n",
    "#                                                 cells_per_block=(1, 1), visualize=True, block_norm='L2-Hys',\n",
    "#                                                 feature_vector=True)\n",
    "    # 设置LBP 特征提取算法的参数\n",
    "    radius = 3\n",
    "    n_points = 8 * radius\n",
    "    #print(gray_image.dtype)\n",
    "    feature_lbp = feature.local_binary_pattern(bin_image, n_points, radius, 'uniform')\n",
    "#     feature_glcm_flattened = feature_glcm.flatten()\n",
    "#     feature_hog_flattened = hog_feature_vector\n",
    "    feature_lbp_flattended = feature_lbp.flatten()\n",
    "    #result = {'glcm': feature_glcm_flattened, 'hog': feature_hog_flattened, 'lbp': feature_lbp_flattended}\n",
    "    result = {'lbp': feature_lbp_flattended}\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lbp_feature = []\n",
    "glcm_feature = []\n",
    "hog_feature = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for img in tqdm(dataset):\n",
    "    image = np.reshape(img, [28, 28])\n",
    "    features = get_features_list(image)\n",
    "    lbp_feature.append(features['lbp'])\n",
    "#     lbp_feature.append(features['glcm'])\n",
    "#     lbp_feature.append(features['hog'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lbp_feature = np.array(lbp_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lbp_feature.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(lbp_feature, label, test_size=0.3, random_state=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_img = np.reshape(dataset[19999, :], [28, 28])\n",
    "plt.imshow(test_img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lbp = get_features_list(test_img)['lbp']\n",
    "lbp = np.reshape(lbp, [1, lbp.shape[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.predict(lbp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lbp_img = np.reshape(lbp, [28,28])\n",
    "plt.imshow(lbp_img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 使用keras 搭建一个简单的CNN 来实现分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Conv1D, Conv2D, MaxPool1D, MaxPool2D, Softmax, GlobalAveragePooling2D, Dense,\\\n",
    "Dropout\n",
    "from keras.optimizers import SGD\n",
    "from keras.callbacks import TensorBoard, ReduceLROnPlateau, ModelCheckpoint\n",
    "from keras.models import Model\n",
    "from keras.utils import to_categorical\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.3\n",
    "set_session(tf.Session(config=config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    input_tensor = Input(shape=(28, 28, 1))\n",
    "    x = Conv2D(filters=64 ,kernel_size=(1,1) ,strides=(1, 1), activation='relu')(input_tensor)\n",
    "    x = MaxPool2D(pool_size=(1, 1), strides=(2,2))(x)\n",
    "    \n",
    "    x = Conv2D(filters=128,kernel_size=(3,3), strides=(1, 1), activation='relu')(x)\n",
    "    x = MaxPool2D(pool_size=(2, 2), strides=(2, 2))(x)\n",
    "    \n",
    "    x = Conv2D(filters=256,kernel_size=(3,3), strides=(1, 1), activation='relu')(x)\n",
    "    x = MaxPool2D(pool_size=(2, 2), strides=(2, 2))(x)     \n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(256)(x)\n",
    "    y = Dense(10,activation='softmax')(x)\n",
    "    model = Model(input=input_tensor, outputs=y)\n",
    "    sgd = SGD(lr=1e-2, momentum=0.9)\n",
    "    model.compile(optimizer=sgd, loss='categorical_crossentropy', metrics=['acc'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zyp/miniconda3/envs/pda/lib/python3.6/site-packages/ipykernel_launcher.py:16: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=Tensor(\"de..., inputs=Tensor(\"in...)`\n",
      "  app.launch_new_instance()\n"
     ]
    }
   ],
   "source": [
    "model = get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 28, 28, 64)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 12, 12, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 6, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 4, 4, 256)         295168    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 2, 2, 256)         0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_1 ( (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 503,306\n",
      "Trainable params: 503,306\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70000, 10)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_one_hot = to_categorical(label)\n",
    "y_one_hot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_img = np.reshape(dataset, [dataset.shape[0], 28, 28, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70000, 28, 28, 1)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(<matplotlib.image.AxesImage at 0x7f1de00b7f28>, None)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.imshow(dataset_img[0][:,:,0]),plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from visualize_feature_map import MyTensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "tb = TensorBoard(log_dir='./log', \n",
    "                 histogram_freq=10, \n",
    "                 batch_size=32\n",
    "                )\n",
    "model_save = ModelCheckpoint('./model/Mnist-CNN-model.h5',\n",
    "                             monitor='val_loss',\n",
    "                             verbose=100,\n",
    "                             save_best_only=True,\n",
    "                             save_weights_only=True, \n",
    "                             mode='auto',\n",
    "                             period=10)\n",
    "lr_reduce = ReduceLROnPlateau(monitor='val_loss', \n",
    "                              factor=0.1, \n",
    "                              patience=10,\n",
    "                              verbose=0, \n",
    "                              mode='auto',\n",
    "                              min_delta=0.0001, \n",
    "                              min_lr=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(dataset_img, y_one_hot, test_size=0.3, random_state=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49000, 28, 28, 1)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 44100 samples, validate on 4900 samples\n",
      "Epoch 1/20\n",
      "44100/44100 [==============================] - 5s 105us/step - loss: 2.2593 - acc: 0.2284 - val_loss: 2.1302 - val_acc: 0.5796\n",
      "Epoch 2/20\n",
      "44100/44100 [==============================] - 2s 47us/step - loss: 1.3073 - acc: 0.6033 - val_loss: 0.6639 - val_acc: 0.8051\n",
      "Epoch 3/20\n",
      "44100/44100 [==============================] - 2s 47us/step - loss: 0.4440 - acc: 0.8624 - val_loss: 0.2627 - val_acc: 0.9182\n",
      "Epoch 4/20\n",
      "44100/44100 [==============================] - 2s 44us/step - loss: 0.2975 - acc: 0.9100 - val_loss: 0.1878 - val_acc: 0.9451\n",
      "Epoch 5/20\n",
      "44100/44100 [==============================] - 2s 45us/step - loss: 0.2324 - acc: 0.9285 - val_loss: 0.1631 - val_acc: 0.9516\n",
      "Epoch 6/20\n",
      "44100/44100 [==============================] - 2s 46us/step - loss: 0.1891 - acc: 0.9426 - val_loss: 0.1885 - val_acc: 0.9371\n",
      "Epoch 7/20\n",
      "44100/44100 [==============================] - 2s 45us/step - loss: 0.1743 - acc: 0.9473 - val_loss: 0.1272 - val_acc: 0.9584\n",
      "Epoch 8/20\n",
      "44100/44100 [==============================] - 2s 43us/step - loss: 0.1481 - acc: 0.9549 - val_loss: 0.1369 - val_acc: 0.9545\n",
      "Epoch 9/20\n",
      "44100/44100 [==============================] - 2s 44us/step - loss: 0.1404 - acc: 0.9586 - val_loss: 0.1145 - val_acc: 0.9618\n",
      "Epoch 10/20\n",
      "44100/44100 [==============================] - 2s 46us/step - loss: 0.1241 - acc: 0.9622 - val_loss: 0.0955 - val_acc: 0.9686\n",
      "\n",
      "Epoch 00010: val_loss improved from inf to 0.09552, saving model to ./model/Mnist-CNN-model.h5\n",
      "Epoch 11/20\n",
      "44100/44100 [==============================] - 2s 45us/step - loss: 0.1144 - acc: 0.9653 - val_loss: 0.0886 - val_acc: 0.9710\n",
      "Epoch 12/20\n",
      "44100/44100 [==============================] - 2s 45us/step - loss: 0.1081 - acc: 0.9669 - val_loss: 0.0837 - val_acc: 0.9722\n",
      "Epoch 13/20\n",
      "44100/44100 [==============================] - 2s 46us/step - loss: 0.1022 - acc: 0.9687 - val_loss: 0.1145 - val_acc: 0.9645\n",
      "Epoch 14/20\n",
      "44100/44100 [==============================] - 2s 44us/step - loss: 0.0960 - acc: 0.9706 - val_loss: 0.0738 - val_acc: 0.9753\n",
      "Epoch 15/20\n",
      "44100/44100 [==============================] - 2s 45us/step - loss: 0.0872 - acc: 0.9726 - val_loss: 0.0927 - val_acc: 0.9710\n",
      "Epoch 16/20\n",
      "44100/44100 [==============================] - 2s 43us/step - loss: 0.0850 - acc: 0.9733 - val_loss: 0.0788 - val_acc: 0.9739\n",
      "Epoch 17/20\n",
      "44100/44100 [==============================] - 2s 44us/step - loss: 0.0774 - acc: 0.9761 - val_loss: 0.0753 - val_acc: 0.9745\n",
      "Epoch 18/20\n",
      "44100/44100 [==============================] - 2s 43us/step - loss: 0.0741 - acc: 0.9769 - val_loss: 0.0699 - val_acc: 0.9765\n",
      "Epoch 19/20\n",
      "44100/44100 [==============================] - 2s 46us/step - loss: 0.0674 - acc: 0.9802 - val_loss: 0.0683 - val_acc: 0.9776\n",
      "Epoch 20/20\n",
      "44100/44100 [==============================] - 2s 44us/step - loss: 0.0672 - acc: 0.9791 - val_loss: 0.0783 - val_acc: 0.9739\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.09552 to 0.07834, saving model to ./model/Mnist-CNN-model.h5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f1f564de048>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train ,batch_size=400,epochs=20,verbose=1,validation_split=0.1,\n",
    "         callbacks=[lr_reduce, model_save, tb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21000/21000 [==============================] - 1s 66us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.07511513172112227, 0.9758571428571429]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_label = np.array([np.argmax(d) for d in y_test])\n",
    "y_pre_label = np.array([np.argmax(d) for d in pred])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21000,)\n",
      "(21000,)\n"
     ]
    }
   ],
   "source": [
    "print(y_test_label.shape)\n",
    "print(y_pre_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9758571428571429"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test_label, y_pre_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 28, 28, 1)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sample = X_test[1001, :, :, :]\n",
    "test_sample = np.reshape(test_sample, [1, test_sample.shape[0], test_sample.shape[1], test_sample.shape[2]])\n",
    "test_sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6.2369465e-09 4.4005267e-13 7.3837603e-10 1.9209171e-08 3.3837873e-11\n",
      "  8.9808651e-08 3.0143916e-09 2.8137223e-13 9.9999952e-01 3.6349377e-07]]\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "test_result = model.predict(test_sample)\n",
    "print(test_result)\n",
    "print(np.argmax(test_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(<matplotlib.image.AxesImage at 0x7f1b400d7cc0>, None)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.imshow(test_sample[0, :,:, 0]),plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
